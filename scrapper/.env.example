# Job Scrapper - Environment Configuration
# Copy this file to .env and fill in your values

# ======================
# Database Configuration
# ======================
# PostgreSQL connection string (required)
# Format: postgres://user:password@host:port/database?sslmode=require
DATABASE_URL=postgres://postgres:your-password@db.your-project.supabase.co:5432/postgres?sslmode=require

# ======================
# Logging Configuration
# ======================
# Log level: DEBUG, INFO, WARN, ERROR (default: INFO)
LOG_LEVEL=INFO

# Log format: json, text (default: text for development, json for production)
LOG_FORMAT=text

# ======================
# Scraper Configuration
# ======================
# Default polite mode delay range in milliseconds (default: 2000-5000)
SCRAPER_DELAY_MIN_MS=2000
SCRAPER_DELAY_MAX_MS=5000

# Default maximum pages to scrape (0 = unlimited)
SCRAPER_DEFAULT_MAX_PAGES=0

# Default days back for job publication filter
SCRAPER_DEFAULT_DAYS_BACK=60

# ==================================
# AI Job Processing Integration
# ==================================
# URL of the AI job processing microservice (optional)
# If set, jobs will be sent to this service after scraping
AI_SERVICE_URL=http://localhost:8081

# AI processing mode: none, process, normalize, translate
# - none: Don't call AI service (default)
# - process: Normalize + translate jobs
# - normalize: Only extract tasks/requirements/offer
# - translate: Only translate original description
AI_PROCESSING_MODE=none
